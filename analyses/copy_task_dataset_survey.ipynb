{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Copy Task dataset survey"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\nThis notebook explores the Copy Task neural recordings that power the Brain-to-Text model. It performs the following steps:\n\n1. Load block-level metadata from `data/t15_copyTaskData_description.csv` to annotate the corpora, speaking strategy, and data split for every trial.\n2. Iterate over the `.hdf5` session files with `model_training.evaluate_model_helpers.load_h5py_file` to extract neural features, labels, and phoneme sequences.\n3. Summarize the dataset via channel-level statistics, sentence length histograms, and baseline phoneme error rate (PER) calculations that can guide future modeling work.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfrom pathlib import Path\nfrom collections import defaultdict\nfrom typing import Dict, List, Tuple, Optional\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom model_training.evaluate_model_helpers import load_h5py_file, LOGIT_TO_PHONEME\nfrom nejm_b2txt_utils.general_utils import calculate_error_rate\n\nsns.set_theme(style=\"whitegrid\", context=\"talk\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nREPO_ROOT = Path.cwd()\nDATA_DIR = REPO_ROOT / \"data\"\nMETADATA_PATH = DATA_DIR / \"t15_copyTaskData_description.csv\"\nHDF5_ROOT = DATA_DIR / \"hdf5_data_final\"\n\n# Optional limits for quick experiments. Set to integers to subsample the workload.\nMAX_FILES: Optional[int] = None\nMAX_TRIALS_PER_FILE: Optional[int] = None\n\nprint(f\"Using data directory: {DATA_DIR}\")\nprint(f\"Expecting HDF5 files under: {HDF5_ROOT}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Load Copy Task metadata"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nraw_metadata_df = pd.read_csv(METADATA_PATH)\nif 'Speaking strategy' not in raw_metadata_df.columns:\n    raw_metadata_df['Speaking strategy'] = 'Unknown'\n\nraw_metadata_df['Block number'] = raw_metadata_df['Block number'].astype(int)\nraw_metadata_df['Date'] = pd.to_datetime(raw_metadata_df['Date']).dt.strftime('%Y-%m-%d')\n\nmetadata_df = raw_metadata_df.rename(columns={\n    'Post-implant day': 'post_implant_day',\n    'Block number': 'block_number',\n    'Number of sentences': 'n_sentences',\n    'Corpus': 'corpus',\n    'Split': 'split',\n    'Speaking strategy': 'speaking_strategy',\n})\nmetadata_df['date'] = metadata_df['Date']\n\nmetadata_lookup = metadata_df.set_index(['date', 'block_number']).to_dict('index')\n\nprint(f\"Metadata rows: {len(metadata_df):,}\")\nmetadata_df.head()\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nmetadata_pivot = metadata_df.groupby(['split', 'corpus'])['n_sentences'].sum().unstack(fill_value=0)\nmetadata_pivot\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Locate neural session files"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nhdf5_files = sorted(HDF5_ROOT.glob('t15.*/*.hdf5'))\nif MAX_FILES:\n    hdf5_files = hdf5_files[:MAX_FILES]\n\nprint(f\"Discovered {len(hdf5_files)} HDF5 files\")\nif not hdf5_files:\n    raise FileNotFoundError(\n        \"No .hdf5 files were found. Download `t15_copyTask_neuralData.zip`, \"\n        \"unzip it, and place the `hdf5_data_final` directory inside `data/`.\"\n    )\n\nhdf5_files[:5]\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Helper functions for decoding and aggregation"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nCHANNEL_GROUPS: List[Tuple[str, Tuple[int, int]]] = [\n    (\"ventral 6v (TC)\", (0, 64)),\n    (\"area 4 (TC)\", (64, 128)),\n    (\"55b (TC)\", (128, 192)),\n    (\"dorsal 6v (TC)\", (192, 256)),\n    (\"ventral 6v (SBP)\", (256, 320)),\n    (\"area 4 (SBP)\", (320, 384)),\n    (\"55b (SBP)\", (384, 448)),\n    (\"dorsal 6v (SBP)\", (448, 512)),\n]\n\ndef session_to_date(session_name: str) -> str:\n    parts = session_name.split('.')\n    if len(parts) >= 4:\n        return f\"{parts[1]}-{parts[2]}-{parts[3]}\"\n    return parts[-1]\n\n\ndef decode_sentence_label(value) -> Optional[str]:\n    if value is None:\n        return None\n    if isinstance(value, bytes):\n        return value.decode('utf-8')\n    if isinstance(value, str):\n        return value\n    arr = np.array(value).flatten()\n    if arr.dtype.kind in {'U', 'S'}:\n        return ''.join(arr.tolist()).strip()\n    return str(value)\n\n\ndef decode_transcription(encoded) -> Optional[str]:\n    if encoded is None:\n        return None\n    arr = np.array(encoded).flatten()\n    chars = []\n    for code in arr:\n        code = int(code)\n        if code == 0:\n            break\n        chars.append(chr(code))\n    return ''.join(chars)\n\n\ndef decode_phoneme_sequence(seq_ids, seq_len) -> List[str]:\n    if seq_ids is None or seq_len is None:\n        return []\n    clipped = [int(p) for p in seq_ids[:seq_len]]\n    return [LOGIT_TO_PHONEME[p] for p in clipped]\n\n\ndef assign_channel_group(channel_idx: int) -> str:\n    for group_name, (start, end) in CHANNEL_GROUPS:\n        if start <= channel_idx < end:\n            return group_name\n    return 'unknown'\n\n\ndef update_channel_stats(stats: Dict[str, Optional[np.ndarray]], features: np.ndarray) -> None:\n    feats = np.asarray(features, dtype=np.float64)\n    if feats.ndim != 2:\n        raise ValueError(f\"Expected 2D features, received shape {feats.shape}\")\n    if stats['sum'] is None:\n        n_channels = feats.shape[1]\n        stats['sum'] = np.zeros(n_channels, dtype=np.float64)\n        stats['sum_sq'] = np.zeros(n_channels, dtype=np.float64)\n        stats['min'] = np.full(n_channels, np.inf, dtype=np.float64)\n        stats['max'] = np.full(n_channels, -np.inf, dtype=np.float64)\n        stats['count'] = 0\n    stats['sum'] += feats.sum(axis=0)\n    stats['sum_sq'] += np.square(feats).sum(axis=0)\n    stats['min'] = np.minimum(stats['min'], feats.min(axis=0))\n    stats['max'] = np.maximum(stats['max'], feats.max(axis=0))\n    stats['count'] += feats.shape[0]\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Load sessions with `load_h5py_file`"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nchannel_stats = {'sum': None, 'sum_sq': None, 'min': None, 'max': None, 'count': 0}\ntrial_records: List[Dict[str, object]] = []\nphoneme_records: List[Dict[str, object]] = []\n\nsentence_lookup: Dict[Tuple[str, str], List[str]] = {}\n\nfor file_idx, file_path in enumerate(hdf5_files):\n    session_payload = load_h5py_file(str(file_path), raw_metadata_df)\n    n_trials = len(session_payload['session'])\n    if MAX_TRIALS_PER_FILE is not None:\n        n_trials = min(n_trials, MAX_TRIALS_PER_FILE)\n\n    for trial_idx in range(n_trials):\n        session_name = session_payload['session'][trial_idx]\n        block_num = int(session_payload['block_num'][trial_idx])\n        trial_num = int(session_payload['trial_num'][trial_idx])\n        n_time_steps = int(session_payload['n_time_steps'][trial_idx])\n\n        session_date = session_to_date(session_name)\n        meta = metadata_lookup.get((session_date, block_num), {})\n        corpus_name = meta.get('corpus', session_payload['corpus'][trial_idx])\n        split_name = meta.get('split', 'Unknown')\n        speaking_strategy = meta.get('speaking_strategy', 'Unknown')\n\n        sentence_label = decode_sentence_label(session_payload['sentence_label'][trial_idx])\n        transcription = decode_transcription(session_payload['transcriptions'][trial_idx])\n        seq_len = session_payload['seq_len'][trial_idx]\n\n        record = {\n            'session': session_name,\n            'session_date': session_date,\n            'block_num': block_num,\n            'trial_num': trial_num,\n            'split': split_name,\n            'corpus': corpus_name,\n            'speaking_strategy': speaking_strategy,\n            'n_time_steps': n_time_steps,\n            'seq_len': int(seq_len) if seq_len is not None else None,\n            'sentence_label': sentence_label,\n            'transcription': transcription,\n        }\n\n        if sentence_label:\n            record['sentence_word_len'] = len(sentence_label.split())\n            record['sentence_char_len'] = len(sentence_label)\n\n        trial_records.append(record)\n\n        neural_features = session_payload['neural_features'][trial_idx]\n        update_channel_stats(channel_stats, neural_features)\n\n        seq_ids = session_payload['seq_class_ids'][trial_idx]\n        if seq_ids is not None and seq_len is not None:\n            phoneme_seq = decode_phoneme_sequence(seq_ids, seq_len)\n            phoneme_records.append({\n                'session': session_name,\n                'block_num': block_num,\n                'trial_num': trial_num,\n                'split': split_name,\n                'corpus': corpus_name,\n                'speaking_strategy': speaking_strategy,\n                'sentence_label': sentence_label or f\"trial_{trial_idx}\",\n                'phonemes': phoneme_seq,\n            })\n            sentence_lookup[(corpus_name, sentence_label)] = phoneme_seq\n\nprint(f\"Loaded {len(trial_records):,} trials across {len(hdf5_files)} files\")\ntrials_df = pd.DataFrame(trial_records)\ntrials_df.head()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Channel statistics"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nif channel_stats['sum'] is None:\n    raise RuntimeError('Channel statistics are unavailable. Make sure at least one trial was loaded.')\n\ncount = channel_stats['count']\nmeans = channel_stats['sum'] / count\nvariances = channel_stats['sum_sq'] / count - np.square(means)\nstds = np.sqrt(np.maximum(variances, 0))\n\nchannel_df = pd.DataFrame({\n    'channel': np.arange(len(means)),\n    'mean': means,\n    'std': stds,\n    'min': channel_stats['min'],\n    'max': channel_stats['max'],\n})\nchannel_df['array'] = channel_df['channel'].apply(assign_channel_group)\nchannel_df.head()\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfig, axes = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\nsns.lineplot(data=channel_df, x='channel', y='mean', hue='array', ax=axes[0])\naxes[0].set_title('Channel mean activity (20 ms bins)')\naxes[0].set_xlabel('Channel index')\naxes[0].set_ylabel('Mean feature value')\naxes[0].legend(title='Array', bbox_to_anchor=(1.02, 1), loc='upper left')\n\nsns.lineplot(data=channel_df, x='channel', y='std', hue='array', ax=axes[1])\naxes[1].set_title('Channel standard deviation')\naxes[1].set_xlabel('Channel index')\naxes[1].set_ylabel('Std. dev.')\naxes[1].legend(title='Array', bbox_to_anchor=(1.02, 1), loc='upper left')\n\nplt.tight_layout()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Sentence length distributions"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nif trials_df.empty:\n    raise RuntimeError('Trial metadata is empty. Verify that the HDF5 files contain labeled trials.')\n\nlength_cols = ['sentence_word_len', 'sentence_char_len']\nfor col in length_cols:\n    trials_df[col] = trials_df[col].fillna(0)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nfor ax, col, label in zip(axes, length_cols, ['Words per sentence', 'Characters per sentence']):\n    sns.histplot(\n        data=trials_df,\n        x=col,\n        hue='split',\n        multiple='stack',\n        bins=30,\n        ax=ax,\n    )\n    ax.set_title(label)\n    ax.set_xlabel(label)\n    ax.set_ylabel('Trials')\nplt.tight_layout()\n\nsns.displot(\n    data=trials_df,\n    x='sentence_word_len',\n    col='corpus',\n    col_wrap=3,\n    hue='split',\n    bins=25,\n    facet_kws={'sharey': False},\n)\nplt.subplots_adjust(top=0.85)\nplt.suptitle('Sentence word-length distributions by corpus')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## PER baselines"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\ndef aggregate_per(targets: List[List[str]], predictions: List[List[str]]):\n    total_err = 0\n    total_len = 0\n    for true_seq, pred_seq in zip(targets, predictions):\n        if not true_seq:\n            continue\n        total_err += calculate_error_rate(true_seq, pred_seq)\n        total_len += len(true_seq)\n    return total_err / total_len if total_len else np.nan\n\nif not phoneme_records:\n    raise RuntimeError('Phoneme annotations were not found. Ensure you are using training/validation files with labels.')\n\nphoneme_targets = [rec['phonemes'] for rec in phoneme_records]\ncorpus_labels = [rec['corpus'] for rec in phoneme_records]\n\nsilence_predictions = [['SIL'] * len(seq) for seq in phoneme_targets]\n\ncorpus_sentence_counts = (\n    pd.DataFrame(phoneme_records)\n    .groupby(['corpus', 'sentence_label'])\n    .size()\n    .reset_index(name='count')\n)\ncorpus_mode = corpus_sentence_counts.loc[\n    corpus_sentence_counts.groupby('corpus')['count'].idxmax()\n][['corpus', 'sentence_label']]\nmode_lookup = dict(zip(corpus_mode['corpus'], corpus_mode['sentence_label']))\n\ncorpus_sentence_map = {\n    (rec['corpus'], rec['sentence_label']): rec['phonemes']\n    for rec in phoneme_records\n}\nmode_predictions = [\n    corpus_sentence_map[(corpus, mode_lookup[corpus])]\n    for corpus in corpus_labels\n]\n\nrng = np.random.default_rng(0)\ncorpus_sequences: Dict[str, List[List[str]]] = defaultdict(list)\nfor rec in phoneme_records:\n    corpus_sequences[rec['corpus']].append(rec['phonemes'])\nrandom_predictions = [\n    corpus_sequences[corpus][rng.integers(len(corpus_sequences[corpus]))]\n    for corpus in corpus_labels\n]\n\nbaseline_results = pd.DataFrame([\n    {'baseline': 'All SIL', 'per': aggregate_per(phoneme_targets, silence_predictions)},\n    {'baseline': 'Corpus mode sentence', 'per': aggregate_per(phoneme_targets, mode_predictions)},\n    {'baseline': 'Random sentence (same corpus)', 'per': aggregate_per(phoneme_targets, random_predictions)},\n]).sort_values('per')\n\nbaseline_results\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfig, ax = plt.subplots(figsize=(8, 4))\nsns.barplot(data=baseline_results, x='baseline', y='per', ax=ax)\nax.set_ylabel('Aggregate PER')\nax.set_xlabel('Baseline strategy')\nax.set_title('Phoneme error rate baselines')\nplt.xticks(rotation=20)\nplt.tight_layout()\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}